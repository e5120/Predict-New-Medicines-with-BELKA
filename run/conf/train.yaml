hydra:
  job:
    name: train
    chdir: true
  run:
    dir: ${dir.model_dir}/${exp_name}/${dir_name}
  sweep:
    dir: ${dir.model_dir}/${exp_name}
    subdir: run${hydra.job.num}

defaults:
  - _self_
  - dir: local
  - dataset: lm_dataset
  - model: lm_model
  - optimizer: radam
  - scheduler: constant

data_dir: /project/data/lb
dir_name: single
exp_name: dummy
stage: train
fold: 0
chunk_size: 5
leak: False
batch_size: 256
seed: 42
num_workers: 5
benchmark: False
logger: False

trainer:
  max_epochs: 150
  min_epochs: 200
  enable_progress_bar: True
  accelerator: auto
  precision: "16-mixed"
  gradient_clip_val: ~
  accumulate_grad_batches: 1
  num_sanity_val_steps: 50
  reload_dataloaders_every_n_epochs: 1
  devices: [0]

# early stopping
early_stopping:
  monitor: "val_map"
  mode: "max"
  patience: 3

# model checkpoint
model_checkpoint:
  save_weights_only: True
  monitor: "val_map"
  mode: "max"
  dirpath: True
  save_top_k: 1
  verbose: 1
