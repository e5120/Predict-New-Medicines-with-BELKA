hydra:
  job:
    name: train
    chdir: true
  run:
    dir: ${dir.model_dir}/${exp_name}/single
  sweep:
    dir: ${dir.model_dir}/${exp_name}
    subdir: run${hydra.job.num}

defaults:
  - _self_
  - dir: local
  - dataset: ~
  - model: ~
  - optimizer: adam
  - scheduler: constant

exp_name: dummy
stage: train
batch_size: 32
n_folds: 5
folds: [0]
gpu_id: 0
seed: 42
num_workers: 2
logger: False

trainer:
  max_epochs: 20
  min_epochs: 100
  enable_progress_bar: True
  accelerator: auto
  precision: "16-mixed"
  gradient_clip_val: ~
  accumulate_grad_batches: 1
  reload_dataloaders_every_n_epochs: 1
  devices: 1

# early stopping
early_stopping:
  monitor: "val_loss"
  mode: "min"
  patience: 5

# model checkpoint
model_checkpoint:
  save_weights_only: True
  monitor: "val_loss"
  mode: "min"
  dirpath: True
  save_top_k: 1
  verbose: 1
